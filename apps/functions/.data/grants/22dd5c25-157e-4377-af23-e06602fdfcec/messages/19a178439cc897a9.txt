New in Pydantic: New Pydantic AI Graph API, SF Meetup &amp; More 📍 Py AI Meetup — San Francisco (Nov 11) Join us in SF for an evening of lightning talks and networking with the Pydantic &amp; FastMCP teams and friends. 🗓️ Date: Tuesday, November 11, 5–8 PM (GMT-8) 📍 Location: San Francisco, CA (address shared on approval) 🎙️ Speakers: Samuel Colvin (Pydantic), Reducto + Modal teams, Adam Azzam (FastMCP), and more Request to Join → 🚦 Pydantic AI Gateway (PAIG) Closed Beta We&#39;re onboarding teams into the Pydantic AI Gateway closed beta. PAIG handles the annoying bits: LLM API key management, per-user spend limits, and multi-provider access with a single key - plus other LLM governance challenges. If you&#39;re interested in trying out the closed beta, please reply to this email. 🕸️ Pydantic AI New Graph API (Beta): Function-based, typed async graphs The new Graph API in pydantic-graph is a builder-style, async, type-safe way to orchestrate complex workflows with parallelism and branching. Define steps with @g.step (instead of subclassing nodes) and wire them together with typed edges. Each step receives a generic StepContext carrying inputs , a shared state , and produces typed outputs - giving you much stronger guarantees than mutating a global state bag. Builder pattern: g.edge_from(...).to(...) connections, joins, and end nodes. Parallelism: g.map() to fan out over iterables; g.broadcast() to send the same value down multiple paths; joins with reducers (e.g. reduce_list_append ). Typed branching: decision steps with input/output typing and exhaustiveness checks. Execution control: iterate with graph.iter() and inspect run events/tasks—even with parallel execution. View the Graph API PR → 📚 Pydantic Evals: New guides &amp; examples We’ve overhauled the Evals docs with concrete how-tos and references: datasets &amp; cases, running experiments, built-in and custom evaluators (incl. LLM-as-a-judge), span-based evaluation via OpenTelemetry/Logfire, metrics &amp; attributes, dataset serialization, concurrency &amp; retry control, plus using Evals with pytest and CI/CD. Quick Start &amp; Core Concepts Built-in evaluators, LLM-Judge, and writing custom evaluators Span-based evaluation &amp; Logfire/OpenTelemetry integration Dataset management &amp; serialization (YAML/JSON) Concurrency, performance &amp; retry strategies Using with pytest (integrate with CI/CD) Explore the Evals Docs → 🚀 In the wild: Microsoft, Guido &amp; AMD using Logfire Microsoft &amp; Guido shared examples featuring Pydantic AI + Logfire instrumentation. AMD showcased Logfire live at PyTorch Conference on their hardware dashboards. Questions or want Gateway access? Hit reply or find us on Slack . The Pydantic Team You&#39;re receiving this because you opted in for Pydantic updates. Unsubscribe GitHub | Website | Community